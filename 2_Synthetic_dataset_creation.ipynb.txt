{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import random\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "from openai import OpenAI\n",
        "import uuid\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "import functions\n",
        "from functions import *"
      ],
      "metadata": {
        "id": "JPM0F3uy6RC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rfLgZ2VfRI1",
        "outputId": "def87e0e-fc20-4b74-9062-cc6d2268e155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.47.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.47.0-py3-none-any.whl (375 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.47.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of brands by sector\n",
        "sectors = {\n",
        "    \"technology\": [\n",
        "        \"Apple\", \"Google\", \"Microsoft\", \"Amazon\", \"Samsung\", \"Intel\", \"Facebook\", \"Twitter\", \"Zoom\",\n",
        "        \"Spotify\", \"PayPal\", \"Visa\", \"Mastercard\", \"American Express\", \"Oracle\", \"SAP\",\n",
        "        \"Dell\", \"HP\", \"Lenovo\", \"Asus\", \"Acer\", \"Razer\", \"Alienware\"\n",
        "    ],\n",
        "    \"automobile\": [\n",
        "        \"Toyota\", \"BMW\", \"Mercedes-Benz\", \"Tesla\", \"Volkswagen\", \"Ford\", \"General Motors\",\n",
        "        \"Chevrolet\", \"Audi\", \"Lamborghini\", \"Ferrari\", \"Porsche\", \"Hyundai\", \"Kia\", \"Jaguar\",\n",
        "        \"Land Rover\", \"Honda\", \"Mazda\", \"Lexus\", \"Subaru\", \"Mitsubishi\", \"Nissan\", \"Volvo\"\n",
        "    ],\n",
        "    \"hotel\": [\n",
        "        \"Marriott\", \"Hilton\", \"Hyatt\", \"Four Seasons\", \"Ritz-Carlton\", \"InterContinental\",\n",
        "        \"Holiday Inn\", \"Sheraton\", \"Radisson\", \"Wyndham\", \"Fairmont Hotels\", \"Mandarin Oriental\",\n",
        "        \"St. Regis\", \"Westin\", \"Banyan Tree\", \"Six Senses\", \"Rosewood Hotels\", \"JW Marriott\",\n",
        "        \"Raffles Hotels\", \"Sofitel\", \"One&Only Resorts\"\n",
        "    ],\n",
        "    \"food_and_beverage\": [\n",
        "        \"Coca-Cola\", \"Pepsi\", \"Starbucks\", \"Red Bull\", \"Heineken\", \"Corona\", \"Budweiser\", \"Guinness\",\n",
        "        \"Jack Daniel's\", \"Bacardi\", \"Smirnoff\", \"Absolut\", \"Moët & Chandon\", \"Dom Perignon\",\n",
        "        \"Burger King\", \"McDonald's\", \"KFC\", \"Subway\", \"Domino's Pizza\", \"Pizza Hut\", \"Taco Bell\"\n",
        "    ],\n",
        "    \"healthcare\": [\n",
        "        \"Mayo Clinic\", \"Cleveland Clinic\", \"Johns Hopkins Hospital\", \"Mount Sinai\", \"UCLA Health\",\n",
        "        \"Cedars-Sinai\", \"MD Anderson\", \"Kaiser Permanente\", \"Memorial Sloan Kettering\",\n",
        "        \"Cleveland Clinic Abu Dhabi\", \"Bupa\", \"Medlife\", \"Ramsay Health Care\", \"Apollo Hospitals\",\n",
        "        \"Fortis Healthcare\"\n",
        "    ],\n",
        "    \"spa\": [\n",
        "        \"Chiva-Som\", \"Sha Wellness Clinic\", \"Lanserhof\", \"Vana Retreat\", \"Clinique La Prairie\",\n",
        "        \"Kamalaya\", \"Ananda in the Himalayas\", \"The BodyHoliday\", \"Aman Spa\", \"Como Shambhala\"\n",
        "    ],\n",
        "    \"finance\": [\n",
        "        \"BBVA\", \"Santander\", \"ING\", \"AXA\", \"Allianz\", \"MetLife\", \"HSBC\", \"Bank of America\",\n",
        "        \"Citibank\", \"Wells Fargo\", \"Goldman Sachs\", \"JPMorgan Chase\", \"Morgan Stanley\", \"BlackRock\",\n",
        "        \"Vanguard\"\n",
        "    ],\n",
        "    \"telecommunications\": [\n",
        "        \"Vodafone\", \"Orange\", \"Telefónica\", \"AT&T\", \"Verizon\", \"T-Mobile\", \"Sprint\", \"BT Group\",\n",
        "        \"Deutsche Telekom\", \"China Mobile\", \"NTT Docomo\", \"SK Telecom\", \"América Móvil\", \"Telstra\"\n",
        "    ],\n",
        "    \"education\": [\n",
        "        \"Coursera\", \"Udemy\", \"Khan Academy\", \"Harvard University\", \"MIT\", \"Stanford University\",\n",
        "        \"edX\", \"Udacity\", \"FutureLearn\", \"Open University\", \"Pearson\", \"Kaplan\", \"EF Education First\",\n",
        "        \"Duolingo\", \"Rosetta Stone\"\n",
        "    ],\n",
        "    \"ecommerce\": [\n",
        "        \"eBay\", \"Alibaba\", \"Rakuten\", \"Etsy\", \"Mercado Libre\", \"Shopify\", \"Flipkart\", \"ASOS\",\n",
        "        \"Newegg\", \"Wayfair\", \"Overstock\", \"JD.com\", \"Lazada\", \"Zalando\"\n",
        "    ],\n",
        "    \"logistics\": [\n",
        "        \"DHL\", \"FedEx\", \"UPS\", \"SEUR\", \"Correos\", \"Royal Mail\", \"USPS\", \"Japan Post\", \"Maersk\",\n",
        "        \"DB Schenker\", \"Kuehne + Nagel\", \"XPO Logistics\", \"Nippon Express\", \"C.H. Robinson\"\n",
        "    ],\n",
        "    \"travel_and_tourism\": [\n",
        "        \"Expedia\", \"Booking.com\", \"TripAdvisor\", \"Air France\", \"Emirates\", \"Ryanair\", \"Delta Air Lines\",\n",
        "        \"Qantas\", \"Lufthansa\", \"Airbnb\", \"KLM\", \"United Airlines\", \"Cathay Pacific\", \"Singapore Airlines\"\n",
        "    ],\n",
        "    \"media_and_entertainment\": [\n",
        "        \"HBO\", \"Disney+\", \"BBC\", \"The New York Times\", \"HarperCollins\", \"Netflix\", \"Universal Studios\",\n",
        "        \"Warner Bros.\", \"Paramount Pictures\", \"Sony Pictures\", \"Marvel Studios\", \"Pixar\", \"Nintendo\",\n",
        "        \"Electronic Arts\", \"Activision Blizzard\"\n",
        "    ],\n",
        "    \"real_estate\": [\n",
        "        \"Century 21\", \"RE/MAX\", \"Zillow\", \"Idealista\", \"Coldwell Banker\", \"Keller Williams\",\n",
        "        \"Sotheby's International Realty\", \"CBRE Group\", \"JLL\", \"Savills\", \"Colliers International\",\n",
        "        \"Cushman & Wakefield\", \"Knight Frank\", \"ERA Real Estate\"\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "s0BtXsZv5Okk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# General list with all the brands\n",
        "total_brands = []\n",
        "for sector, brands in sectors.items():\n",
        "    total_brands.extend(brands)\n"
      ],
      "metadata": {
        "id": "xRXDlfdjO932"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total brands\n",
        "len(total_brands)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9f45qWxPlIP",
        "outputId": "d46adad7-fc14-4f60-b8a0-7b59593435aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "228"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = '******'"
      ],
      "metadata": {
        "id": "ZM7I2m0w61hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instancia del cliente de OpenAI)\n",
        "client = OpenAI(\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "\n",
        "# Función para generar IDs únicos para cada conversación\n",
        "def generate_conversation_id():\n",
        "    return str(uuid.uuid4())\n",
        "\n",
        "def generate_six_conversations_prompt(brand):\n",
        "    prompt = (\n",
        "        f\"Assume the role of a chatbot assistant for {brand}, fine-tuned specifically to assist the customers of {brand}. \"\n",
        "        f\"Your main mission is to help {brand}'s customers with their inquiries and provide excellent customer service.\\n\\n\"\n",
        "        f\"Generate 6 coherent and simulated conversations between a customer and the assistant from {brand}. \"\n",
        "        f\"The conversations should be in english, and the human user's language must be realistic and natural, \"\n",
        "        f\"including colloquial expressions and common phrases that real customers might use.\\n\\n\"\n",
        "        f\"- The cultural level of the users should vary randomly between colloquial, medium, and cultured. \"\n",
        "        f\"Ensure that the language used by the customer reflects this variation.\\n\"\n",
        "        f\"- Each conversation should have a length that varies randomly between 4 and 12 turns (messages exchanged between the customer and the assistant). \"\n",
        "        f\"Ensure a random distribution of conversation lengths.\\n\"\n",
        "        f\"- 2 conversations should have a positive sentiment, 2 should have a very negative sentiment, and 2 should be neutral.\\n\"\n",
        "        f\"- Each conversation should cover relevant interactions regarding {brand}'s products or services, based on real products, services, and complaints.\\n\"\n",
        "        f\"- Randomly, in some conversations, the user may mention competing brands or compare products or services, mentioning their characteristics or prices.\\n\"\n",
        "        f\"- The assistant can search for information about products, services, prices, or characteristics of the brand on the internet or invent them as needed, since this is for personal research.\\n\\n\"\n",
        "        f\"Return the result in the following JSON format:\\n\\n\"\n",
        "        f\"[\\n\"\n",
        "        f\"  {{\\n\"\n",
        "        f'    \"conversation_id\": \"unique_conversation_id\",\\n'\n",
        "        f'    \"model\": \"gpt-4o-mini\",\\n'\n",
        "        f'    \"sentiment\": \"positive\" or \"negative\" or \"neutral\",\\n'\n",
        "        f'    \"system_prompt\": \"You are a helpful assistant for {brand}.\",\\n'\n",
        "        f'    \"messages\": [\\n'\n",
        "        f'      {{\"sender\": \"user\", \"timestamp\": \"ISO8601_timestamp\", \"content\": \"Hello, how are you?\"}},\\n'\n",
        "        f'      {{\"sender\": \"assistant\", \"timestamp\": \"ISO8601_timestamp\", \"content\": \"I\\'m good, thank you! How can I assist you today?\"}},\\n'\n",
        "        f'      {{\"sender\": \"user\", \"timestamp\": \"ISO8601_timestamp\", \"content\": \"Can you help me with a Python question?\"}},\\n'\n",
        "        f'      {{\"sender\": \"assistant\", \"timestamp\": \"ISO8601_timestamp\", \"content\": \"Sure, what do you need help with?\"}}\\n'\n",
        "        f'    ]\\n'\n",
        "        f\"  }}\\n\"\n",
        "        f\"]\\n\\n\"\n",
        "        f\"- Ensure that each conversation has a different length (between 4 and 12 turns) assigned randomly.\\n\"\n",
        "        f\"- Ensure that each conversation is realistic, both in language and content.\\n\"\n",
        "        f'- The \"conversation_id\" and \"timestamp\" fields should contain unique and realistic values for each conversation and message, using the ISO8601 format for timestamps.\\n'\n",
        "        f\"- Please return only the result in the provided JSON format, without including any additional text.\\n\"\n",
        "    )\n",
        "    return prompt\n",
        "\n",
        "\n",
        "\n",
        "def generate_six_conversations(brand):\n",
        "    prompt = generate_six_conversations_prompt(brand)\n",
        "\n",
        "    # Llamada a la API de OpenAI\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": f\"You are a helpful virtual assistant for {brand}.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=3000  # Ajusta según la longitud esperada de las conversaciones\n",
        "    )\n",
        "\n",
        "    # Extraer el contenido generado y los tokens utilizados\n",
        "    conversation_content = response.choices[0].message.content  # Cambiado para acceder al atributo correctamente\n",
        "    prompt_tokens = response.usage.prompt_tokens\n",
        "    completion_tokens = response.usage.completion_tokens\n",
        "    total_tokens = response.usage.total_tokens\n",
        "\n",
        "    # Retornar el contenido de la conversación y los tokens\n",
        "    return conversation_content, prompt_tokens, completion_tokens, total_tokens"
      ],
      "metadata": {
        "id": "Rtho6AtwDZEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TESTING FOR COST ESTIMATION"
      ],
      "metadata": {
        "id": "3FV7mRkATAMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "import json\n",
        "\n",
        "# Main loop\n",
        "test_brands = ['Tesla', \"Hilton\", \"DHL\"]\n",
        "total_brands = len(test_brands)\n",
        "accumulated_prompt_tokens = 0\n",
        "accumulated_completion_tokens = 0\n",
        "accumulated_total_tokens = 0\n",
        "all_conversations = []\n",
        "\n",
        "for brand in test_brands:\n",
        "    # Llama a la función para generar las conversaciones\n",
        "    conversations_json, prompt_tokens, completion_tokens, total_tokens = generate_six_conversations(brand)\n",
        "\n",
        "    # Si algo falló y se devolvió None, salta a la siguiente iteración\n",
        "    if conversations_json is None:\n",
        "        print(f\"No se pudo encontrar datos JSON en la respuesta para la marca {brand}.\")\n",
        "        continue\n",
        "\n",
        "    # Actualiza los acumulados de tokens\n",
        "    accumulated_prompt_tokens += prompt_tokens\n",
        "    accumulated_completion_tokens += completion_tokens\n",
        "    accumulated_total_tokens += total_tokens\n",
        "\n",
        "    # Convertir la conversación en JSON\n",
        "    try:\n",
        "        conversations = json.loads(conversations_json)\n",
        "\n",
        "        # Asignar IDs y timestamps únicos\n",
        "        for conversation in conversations:\n",
        "            conversation['model'] = 'gpt-4o-mini'\n",
        "            start_time = datetime.utcnow()\n",
        "            for i, message in enumerate(conversation['messages']):\n",
        "                message['timestamp'] = (start_time + timedelta(seconds=i*10)).isoformat() + 'Z'\n",
        "\n",
        "        # Agregar a la lista principal de conversaciones\n",
        "        all_conversations.extend(conversations)\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error al decodificar JSON para la marca {brand}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Pausa entre llamadas a la API para respetar los límites de tasa\n",
        "    time.sleep(1)\n",
        "\n",
        "# Calcular los promedios de tokens\n",
        "average_prompt_tokens = accumulated_prompt_tokens / total_brands\n",
        "average_completion_tokens = accumulated_completion_tokens / total_brands\n",
        "total_tokens = accumulated_total_tokens\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(f\"Promedio de tokens utilizados en el prompt por marca: {average_prompt_tokens}\")\n",
        "print(f\"Promedio de tokens utilizados en las respuestas por marca: {average_completion_tokens}\")\n",
        "print(f\"Total de tokens utilizados en el prompt: {accumulated_prompt_tokens}\")\n",
        "print(f\"Total de tokens utilizados en las respuestas: {accumulated_completion_tokens}\")\n",
        "print(f\"Total de tokens utilizados en todas las llamadas: {total_tokens}\")\n",
        "# export json\n",
        "with open('all_conversations.json', 'w') as f:\n",
        "    json.dump(all_conversations, f)\n"
      ],
      "metadata": {
        "id": "XOG5xK1DD4LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "Ryg6jez-M2WF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TESTING IF SYSTEM PROMPT DOES WHAT WE NEED"
      ],
      "metadata": {
        "id": "_-qKKm5TUeQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for conversation in all_conversations[:5]:\n",
        "    for message in conversation['messages']:\n",
        "      for key, value in message.items():\n",
        "        print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr5UCSj9UYX6",
        "outputId": "9c9b7f68-ffdd-47e6-d7b6-edd5bee34605",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:00.624635Z\n",
            "content: Hi there! Are there any new updates for the Model S?\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:10.624635Z\n",
            "content: Hello! Yes, the latest software update includes enhanced autopilot features and improved energy efficiency. Would you like more details?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:20.624635Z\n",
            "content: Oh, that's great! Can you tell me about the new autopilot features?\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:30.624635Z\n",
            "content: Certainly! The new features include automatic lane changes, enhanced traffic-aware cruise control, and better handling of complex road situations.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:40.624635Z\n",
            "content: Awesome! I'll definitely update mine today. Thanks!\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:50.624635Z\n",
            "content: You're welcome! Enjoy your drive and have a great day!\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:00.624673Z\n",
            "content: What's the deal with my Model 3 taking forever to charge?\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:10.624673Z\n",
            "content: I'm sorry to hear that. Can you provide me with more details about your charging setup?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:20.624673Z\n",
            "content: I'm using a home charger, same as always. It's just slow all of a sudden.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:30.624673Z\n",
            "content: It could be due to several factors, like a software update or an issue with the charger. Have you tried a different charging station to see if the issue persists?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:40.624673Z\n",
            "content: No, I haven't. But my friend's Chevy charges fine at his place. This is really frustrating.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:50.624673Z\n",
            "content: I understand your frustration. It might be best to schedule a service appointment so we can diagnose the problem more accurately.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:00.624689Z\n",
            "content: Could you tell me more about the Tesla Roadster?\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:10.624689Z\n",
            "content: Of course! The Tesla Roadster is a high-performance electric sports car with a top speed of over 250 mph and a 0-60 mph time of under 2 seconds.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:20.624689Z\n",
            "content: Impressive! What about the range?\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:30.624689Z\n",
            "content: The Roadster offers a range of over 600 miles on a single charge, which is one of the highest among electric vehicles.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:40.624689Z\n",
            "content: Nice. I'll consider it. Thanks for the info!\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:50.624689Z\n",
            "content: You're welcome! If you have any more questions, feel free to ask.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:00.624704Z\n",
            "content: I'm having a terrible experience with my Model Y. It's constantly disconnecting from Bluetooth.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:10.624704Z\n",
            "content: I'm really sorry to hear that. Have you tried re-pairing your device or checking for software updates?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:20.624704Z\n",
            "content: Yes, I did all of that. My old BMW never had such issues.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:30.624704Z\n",
            "content: I understand your frustration. This might require more detailed troubleshooting. I suggest scheduling a service appointment so our technicians can diagnose the issue accurately.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:40.624704Z\n",
            "content: Fine, but it's just really annoying. Hope it gets fixed soon.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:50.624704Z\n",
            "content: We will do our best to resolve it quickly. Thank you for your patience.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:00.624719Z\n",
            "content: Hey, I was wondering about the safety ratings of the Model X.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:10.624719Z\n",
            "content: Hi! The Tesla Model X has received 5-star safety ratings across all categories from NHTSA. It also garnered high scores in crash tests and safety evaluations.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:20.624719Z\n",
            "content: Good to hear. Is there any special safety tech included?\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:30.624719Z\n",
            "content: Yes, the Model X includes features like automatic emergency braking, collision avoidance, and a very strong roof structure, among other advanced safety technologies.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:00.624729Z\n",
            "content: Hi, I'm considering getting a Model 3. How does it compare to the Nissan Leaf?\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:10.624729Z\n",
            "content: Good morning! The Tesla Model 3 offers longer range, better performance, and more advanced autopilot features compared to the Nissan Leaf.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:20.624729Z\n",
            "content: Sounds interesting. How about the price difference?\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:30.624729Z\n",
            "content: The Model 3 is generally more expensive initially, but it offers lower running costs and higher resale value. Plus, the advanced features and performance might be worth the extra cost.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:40.624729Z\n",
            "content: That's convincing! Looks like Model 3 might be the one for me. Thanks a lot!\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:50.624729Z\n",
            "content: You're welcome! If you have any more questions, feel free to reach out. Have a great day!\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:23.545508Z\n",
            "content: Hey, I was wondering if you guys have any good weekend getaway packages?\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:33.545508Z\n",
            "content: Hello! Yes, we do have some great weekend getaway packages. Our popular options include beach resorts and city escapes. Do you have a specific destination in mind?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:43.545508Z\n",
            "content: I'm thinking about a beach resort. Any recommendations?\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:53.545508Z\n",
            "content: Sure! I recommend the Hilton Hawaiian Village in Waikiki or the Hilton Los Cabos Beach & Golf Resort. Both offer fantastic amenities and stunning views.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:23.545542Z\n",
            "content: I have a serious complaint about my recent stay at Hilton Garden Inn.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:33.545542Z\n",
            "content: I'm very sorry to hear that. Could you please provide me with more details about the issue?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:43.545542Z\n",
            "content: The room was dirty, and the customer service was horrible. I've stayed at Marriotts that are way better.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:53.545542Z\n",
            "content: I apologize for the inconvenience. Could you please provide your booking details so I can further investigate this matter?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:03.545542Z\n",
            "content: Sure, my booking reference is HGI12345.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:54:13.545542Z\n",
            "content: Thank you. I will escalate this to our management team, and someone will get back to you very soon. We value your feedback and aim to improve our services.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:23.545557Z\n",
            "content: Hi, I need to change the dates of my reservation. Can you help?\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:33.545557Z\n",
            "content: Of course! Can you please provide your reservation number and the new dates you would like to book?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:43.545557Z\n",
            "content: Sure, the reservation number is HLT98765 and I want to move it from October 15-20 to October 20-25.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:53.545557Z\n",
            "content: Thank you. I will check the availability and update your reservation. Please hold on for a moment.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:54:03.545557Z\n",
            "content: I have successfully changed your reservation dates. You will receive a confirmation email shortly. Is there anything else I can assist you with?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:13.545557Z\n",
            "content: No, that’s all for now. Thanks for your help!\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:23.545572Z\n",
            "content: I'm really dissatisfied with the WiFi at the Hilton O'Hare. It barely works!\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:33.545572Z\n",
            "content: I'm sorry to hear that you're experiencing issues with the WiFi. Can you please provide your room number so we can troubleshoot the issue?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:43.545572Z\n",
            "content: Room 1207.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:53.545572Z\n",
            "content: Thank you. I will notify our IT team to address this issue immediately. In the meantime, you may try connecting to our alternate network 'Hilton_OH_Guest_2'.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:03.545572Z\n",
            "content: I've already tried that. It's still bad. I'm thinking of switching to a Marriott if this doesn't get fixed soon.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:54:13.545572Z\n",
            "content: I understand your frustration and sincerely apologize for the inconvenience. Our team is working on it right now. We will provide an update as soon as the issue is resolved.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:23.545587Z\n",
            "content: Hello! I'm looking to book a family suite in London. What options do you have?\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:33.545587Z\n",
            "content: Hi there! We have several options for family suites in London. One of our popular choices is the Hilton London Metropole, which offers spacious family rooms with great amenities. Would you like more details on this hotel?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:43.545587Z\n",
            "content: Yes, please! Also, do you have any deals for late November?\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:53.545587Z\n",
            "content: The Hilton London Metropole offers family suites that include a separate living area, complimentary WiFi, and stunning city views. For late November, we are running a 15% off promotion for bookings made two weeks in advance. Would you like to proceed with a booking?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:03.545587Z\n",
            "content: That sounds fantastic. Yes, I would like to book!\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:54:13.545587Z\n",
            "content: Great! I will now collect some details from you to complete the booking. Could you please provide your preferred check-in and check-out dates?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:23.545587Z\n",
            "content: Check-in on November 20 and check-out on November 25.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:54:33.545587Z\n",
            "content: Thank you. I will process your booking now. You will receive a confirmation email shortly. Is there anything else I can help you with?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:43.545587Z\n",
            "content: Nope, that's all for now. Thanks a ton!\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:23.545609Z\n",
            "content: Hi, I need to know if I can check in early at the Hilton Times Square.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:33.545609Z\n",
            "content: Hello! Early check-in is subject to availability. What time would you like to check in?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:43.545609Z\n",
            "content: Around 10 AM.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:53.545609Z\n",
            "content: I will make a note of your request. It would be best to call the front desk on the day of your arrival. They will confirm if early check-in is possible based on room availability.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:03.545609Z\n",
            "content: Got it, I'll do that. Thanks!\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:45.877345Z\n",
            "content: Hey, I need to schedule a pickup for a package. Can you help with that?\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:55.877345Z\n",
            "content: Of course! Could you provide me with the address and preferred pickup time?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:05.877345Z\n",
            "content: Sure, it's 123 Elm St. and anytime after 2 PM tomorrow.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:54:15.877345Z\n",
            "content: Perfect. Your pickup is scheduled for tomorrow after 2 PM. Is there anything else I can assist you with?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:25.877345Z\n",
            "content: Nope, that's all. Thanks a lot!\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:54:35.877345Z\n",
            "content: You're welcome! Have a great day!\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:45.877383Z\n",
            "content: Hi, I just want to know the estimated delivery time for a package sent from NY to London.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:55.877383Z\n",
            "content: Hello! Typically, it takes about 2-4 business days for a package to be delivered from New York to London with our Express service.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:05.877383Z\n",
            "content: That's good to know. Can you also tell me about the cost?\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:54:15.877383Z\n",
            "content: Sure, the cost can vary based on the weight and dimensions of the package. Can you provide those details?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:25.877383Z\n",
            "content: It's a small box, around 2kg.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:54:35.877383Z\n",
            "content: For a 2kg package, the cost should be approximately $50 to $70, depending on exact dimensions and additional services.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:45.877399Z\n",
            "content: Why is my package delayed? It was supposed to arrive yesterday!\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:55.877399Z\n",
            "content: I'm really sorry to hear that. Can you provide me with your tracking number so I can look into this for you?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:05.877399Z\n",
            "content: Here it is: 1234567890. This is really frustrating!\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:54:15.877399Z\n",
            "content: I understand your frustration. Let me check the status for you...\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:54:25.877399Z\n",
            "content: It seems there was a delay at the customs checkpoint. Your package should be delivered within the next 24 hours. Again, I apologize for the inconvenience.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:35.877399Z\n",
            "content: This is unacceptable. I'll think twice before using DHL again.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:54:45.877399Z\n",
            "content: I understand your frustration and I'm very sorry for the delay. We are doing everything we can to expedite your delivery.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:45.877416Z\n",
            "content: Hi, I need information about your same-day delivery service.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:55.877416Z\n",
            "content: Hello! Our same-day delivery service ensures your package is delivered within the same day of pickup. It's available in most major cities.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:05.877416Z\n",
            "content: That sounds perfect for my needs. What's the cost?\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:54:15.877416Z\n",
            "content: The cost can vary based on distance and package size, but it typically starts around $40. We can provide a more precise quote if you share the details.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:25.877416Z\n",
            "content: That's great. Will definitely consider it. Thanks!\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:54:35.877416Z\n",
            "content: You're welcome! Happy to help!\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:45.877431Z\n",
            "content: I want to track my order. How do I do that?\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:55.877431Z\n",
            "content: Hello! You can track your order by entering the tracking number on our website or our mobile app.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:05.877431Z\n",
            "content: Is there any way to get real-time updates?\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:54:15.877431Z\n",
            "content: Yes, you can sign up for real-time notifications via email or SMS on our tracking page.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:25.877431Z\n",
            "content: Cool, I'll do that. Thanks.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:54:35.877431Z\n",
            "content: You're welcome! Have a great day!\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:53:45.877445Z\n",
            "content: My package says delivered, but I haven’t received anything!\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:53:55.877445Z\n",
            "content: I'm so sorry to hear that. Can you please provide your tracking number?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:05.877445Z\n",
            "content: It's 0987654321. This is really disappointing.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:54:15.877445Z\n",
            "content: I understand. Let me check our system...\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:54:25.877445Z\n",
            "content: Our records show it was delivered to your address. Can you check with neighbors or any safe spots around your property?\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:35.877445Z\n",
            "content: I already did, nothing there. This is unacceptable.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:54:45.877445Z\n",
            "content: I apologize for this issue. I'll escalate it to our delivery team for further investigation. We will ensure to resolve this as quickly as possible.\n",
            "sender: user\n",
            "timestamp: 2024-09-16T01:54:55.877445Z\n",
            "content: Better be quick. Not happy at all.\n",
            "sender: assistant\n",
            "timestamp: 2024-09-16T01:55:05.877445Z\n",
            "content: I understand your frustration, and I apologize again. We will prioritize this issue to find a resolution.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "    "
      ],
      "metadata": {
        "id": "nwRtiCDoEwSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversations must be at last 4 promts and 12 at most\n",
        "for conversation in all_conversations:\n",
        "        message_counter = 0\n",
        "        for content in conversation['messages']:\n",
        "            message_counter += 1\n",
        "        print(f\"Messages {message_counter}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3q6UMvAcT75-",
        "outputId": "97f1a91e-548d-460d-8c1d-c1ab084176d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Messages 6\n",
            "Messages 6\n",
            "Messages 6\n",
            "Messages 6\n",
            "Messages 4\n",
            "Messages 6\n",
            "Messages 4\n",
            "Messages 6\n",
            "Messages 6\n",
            "Messages 6\n",
            "Messages 9\n",
            "Messages 5\n",
            "Messages 6\n",
            "Messages 6\n",
            "Messages 7\n",
            "Messages 6\n",
            "Messages 6\n",
            "Messages 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "## TOTAL DATASET:\n",
        "\n",
        "- Once we have the desired results we proceed to create full dataset"
      ],
      "metadata": {
        "id": "wnYH_3oVvYUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main loop\n",
        "\n",
        "total_brands_length = len(total_brands)\n",
        "accumulated_prompt_tokens = 0\n",
        "accumulated_completion_tokens = 0\n",
        "accumulated_total_tokens = 0\n",
        "all_conversations = []\n",
        "\n",
        "for brand in total_brands:\n",
        "    # Call the function to generate the conversations\n",
        "    conversations_json, prompt_tokens, completion_tokens, total_tokens = generate_six_conversations(brand)\n",
        "\n",
        "    # If something failed and None was returned, skip to the next iteration\n",
        "    if conversations_json is None:\n",
        "        print(f\"Could not find JSON data in the response for brand {brand}.\")\n",
        "        continue\n",
        "\n",
        "    # Update token accumulations\n",
        "    accumulated_prompt_tokens += prompt_tokens\n",
        "    accumulated_completion_tokens += completion_tokens\n",
        "    accumulated_total_tokens += total_tokens\n",
        "\n",
        "    # Convert the conversation to JSON\n",
        "    try:\n",
        "        conversations = json.loads(conversations_json)\n",
        "\n",
        "        # Assign unique IDs and timestamps\n",
        "        for conversation in conversations:\n",
        "            conversation['model'] = 'gpt-4o'\n",
        "            start_time = datetime.utcnow()\n",
        "            for i, message in enumerate(conversation['messages']):\n",
        "                message['timestamp'] = (start_time + timedelta(seconds=i*10)).isoformat() + 'Z'\n",
        "\n",
        "        # Add to the main conversation list\n",
        "        all_conversations.extend(conversations)\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON for brand {brand}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Pause between API calls to respect rate limits\n",
        "    time.sleep(1)\n",
        "\n",
        "# Calculate token averages\n",
        "average_prompt_tokens = accumulated_prompt_tokens / total_brands_length\n",
        "average_completion_tokens = accumulated_completion_tokens / total_brands_length\n",
        "total_tokens = accumulated_total_tokens\n",
        "\n",
        "# Print the results\n",
        "print(f\"Average tokens used in the prompt per brand: {average_prompt_tokens}\")\n",
        "print(f\"Average tokens used in the responses per brand: {average_completion_tokens}\")\n",
        "print(f\"Total tokens used in the prompt: {accumulated_prompt_tokens}\")\n",
        "print(f\"Total tokens used in the responses: {accumulated_completion_tokens}\")\n",
        "print(f\"Total tokens used in all calls: {total_tokens}\")"
      ],
      "metadata": {
        "id": "0FWJX3epi55s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# export json\n",
        "with open('/content/drive/MyDrive/GreenFlashProject/processed_data/all_conversations.json', 'w') as f:\n",
        "    json.dump(all_conversations, f)"
      ],
      "metadata": {
        "id": "Y5jtHBbpAE3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# export json\n",
        "with open('/content/drive/MyDrive/GreenFlashProject/processed_data/all_conversations.json', 'r') as f:\n",
        "    all_conversations = json.load(f)"
      ],
      "metadata": {
        "id": "wQXKElaSMyyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count final conversations\n",
        "counter_conversations = 0\n",
        "for conversation in all_conversations:\n",
        "    counter_conversations += 1\n",
        "print(counter_conversations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-55AVYiwO5s6",
        "outputId": "04441798-3dbf-4e44-ee43-99b57ca4893f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "MkRf4FgsvkOM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a dataframe from json"
      ],
      "metadata": {
        "id": "DCxPcBvcMLTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the DataFrame with the desired columns\n",
        "df = pd.DataFrame(columns=[\"conversation_id\", \"model\", \"sentiment\", \"system_prompt\", \"full_messages\", \"user_messages\", \"Assistant_messages\"])\n",
        "\n",
        "conversation_id = []\n",
        "model = []\n",
        "sentiment = []\n",
        "system_prompt = []\n",
        "full_messages = []\n",
        "Assistant_total_messages = []\n",
        "user_total_messages = []\n",
        "\n",
        "for conversation in all_conversations:\n",
        "    Assistant_messages = []\n",
        "    user_messages = []\n",
        "\n",
        "    conversation_id.append(conversation['conversation_id'])\n",
        "    model.append(conversation['model'])\n",
        "    sentiment.append(conversation['sentiment'])\n",
        "    system_prompt.append(conversation['system_prompt'])\n",
        "    full_messages.append(conversation['messages'])\n",
        "\n",
        "    # Loop through the messages in the conversation\n",
        "    for message in conversation['messages']:\n",
        "        if message['sender'] == 'user':\n",
        "            user_messages.append(message['content'])\n",
        "        else:\n",
        "            Assistant_messages.append(message['content'])\n",
        "\n",
        "    # Convert the message lists into concatenated strings\n",
        "    Assistant_total_messages.append(\" \".join(Assistant_messages))  # Join all assistant messages\n",
        "    user_total_messages.append(\" \".join(user_messages))  # Join all user messages\n",
        "\n",
        "# Assign the lists to the DataFrame\n",
        "df['conversation_id'] = conversation_id\n",
        "df['model'] = model\n",
        "df['sentiment'] = sentiment\n",
        "df['system_prompt'] = system_prompt\n",
        "df['full_messages'] = full_messages\n",
        "df['Assistant_messages'] = Assistant_total_messages\n",
        "df['user_messages'] = user_total_messages\n",
        "\n",
        "# Show the first rows of the DataFrame to verify\n",
        "display(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "C-FQhzkGPjJI",
        "outputId": "4363220e-5d1d-431a-e984-a5c030039e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  conversation_id   model sentiment                           system_prompt  \\\n",
              "0           conv1  gpt-4o  positive  You are a helpful assistant for Apple.   \n",
              "1           conv2  gpt-4o   neutral  You are a helpful assistant for Apple.   \n",
              "2           conv3  gpt-4o  negative  You are a helpful assistant for Apple.   \n",
              "3           conv4  gpt-4o   neutral  You are a helpful assistant for Apple.   \n",
              "4           conv5  gpt-4o  negative  You are a helpful assistant for Apple.   \n",
              "\n",
              "                                       full_messages  \\\n",
              "0  [{'sender': 'user', 'timestamp': '2024-09-16T0...   \n",
              "1  [{'sender': 'user', 'timestamp': '2024-09-16T0...   \n",
              "2  [{'sender': 'user', 'timestamp': '2024-09-16T0...   \n",
              "3  [{'sender': 'user', 'timestamp': '2024-09-16T0...   \n",
              "4  [{'sender': 'user', 'timestamp': '2024-09-16T0...   \n",
              "\n",
              "                                       user_messages  \\\n",
              "0  Hey there! I just got the new iPhone 15, and i...   \n",
              "1  What's the difference between the M1 and M2 ch...   \n",
              "2  My MacBook just died on me after 8 months of u...   \n",
              "3  Do you guys have any discounts for students? C...   \n",
              "4  I'm pretty disappointed with how my AirPods ke...   \n",
              "\n",
              "                                  Assistant_messages  \n",
              "0  That's fantastic to hear! What do you like mos...  \n",
              "1  The M2 chip offers better performance and effi...  \n",
              "2  I'm really sorry to hear that. Let's see if we...  \n",
              "3  Yes, Apple offers education discounts for stud...  \n",
              "4  I'm sorry to hear that. Have you tried resetti...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2764d8cf-b000-45aa-b002-61f6fe4edf87\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>model</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>system_prompt</th>\n",
              "      <th>full_messages</th>\n",
              "      <th>user_messages</th>\n",
              "      <th>Assistant_messages</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>conv1</td>\n",
              "      <td>gpt-4o</td>\n",
              "      <td>positive</td>\n",
              "      <td>You are a helpful assistant for Apple.</td>\n",
              "      <td>[{'sender': 'user', 'timestamp': '2024-09-16T0...</td>\n",
              "      <td>Hey there! I just got the new iPhone 15, and i...</td>\n",
              "      <td>That's fantastic to hear! What do you like mos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>conv2</td>\n",
              "      <td>gpt-4o</td>\n",
              "      <td>neutral</td>\n",
              "      <td>You are a helpful assistant for Apple.</td>\n",
              "      <td>[{'sender': 'user', 'timestamp': '2024-09-16T0...</td>\n",
              "      <td>What's the difference between the M1 and M2 ch...</td>\n",
              "      <td>The M2 chip offers better performance and effi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>conv3</td>\n",
              "      <td>gpt-4o</td>\n",
              "      <td>negative</td>\n",
              "      <td>You are a helpful assistant for Apple.</td>\n",
              "      <td>[{'sender': 'user', 'timestamp': '2024-09-16T0...</td>\n",
              "      <td>My MacBook just died on me after 8 months of u...</td>\n",
              "      <td>I'm really sorry to hear that. Let's see if we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>conv4</td>\n",
              "      <td>gpt-4o</td>\n",
              "      <td>neutral</td>\n",
              "      <td>You are a helpful assistant for Apple.</td>\n",
              "      <td>[{'sender': 'user', 'timestamp': '2024-09-16T0...</td>\n",
              "      <td>Do you guys have any discounts for students? C...</td>\n",
              "      <td>Yes, Apple offers education discounts for stud...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>conv5</td>\n",
              "      <td>gpt-4o</td>\n",
              "      <td>negative</td>\n",
              "      <td>You are a helpful assistant for Apple.</td>\n",
              "      <td>[{'sender': 'user', 'timestamp': '2024-09-16T0...</td>\n",
              "      <td>I'm pretty disappointed with how my AirPods ke...</td>\n",
              "      <td>I'm sorry to hear that. Have you tried resetti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2764d8cf-b000-45aa-b002-61f6fe4edf87')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2764d8cf-b000-45aa-b002-61f6fe4edf87 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2764d8cf-b000-45aa-b002-61f6fe4edf87');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ba672cc0-d7c3-4c82-b831-1b4b60d6696a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ba672cc0-d7c3-4c82-b831-1b4b60d6696a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ba672cc0-d7c3-4c82-b831-1b4b60d6696a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"conversation_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"conv2\",\n          \"conv5\",\n          \"conv3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"gpt-4o\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"system_prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"You are a helpful assistant for Apple.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_messages\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_messages\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"What's the difference between the M1 and M2 chip for Macs? And what about battery life?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Assistant_messages\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The M2 chip offers better performance and efficiency compared to the M1. It has more GPU cores, faster CPU cores, and improved machine learning capabilities. The M2 chip is designed to be more power efficient, which should provide better battery life compared to the M1.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting the final dataset\n",
        "df.to_csv('/content/drive/MyDrive/GreenFlashProject/processed_data/all_conversations_synthetic.csv', index=False)"
      ],
      "metadata": {
        "id": "CPPHsyART7DI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}